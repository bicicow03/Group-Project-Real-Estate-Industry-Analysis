{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d663f90",
   "metadata": {},
   "source": [
    "# MAST30034 Project 2 Group 1 Summary Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7634c7",
   "metadata": {},
   "source": [
    "## 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271a15c",
   "metadata": {},
   "source": [
    "### Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24abd3",
   "metadata": {},
   "source": [
    "#### External datasets\n",
    "- **ABS Census data:** Downloaded from ABS Census DataPacks - General Community Profile. As of 2021.\n",
    "- **Crime data:**: Downloaded from Crime Statstics Agency - Criminal incident by LGA - Year Ending Mar 2025.\n",
    "- **Population data:** Downloaded from Department of Transport and Planning. VIF2023 Victoria Demographic Projections to 2051\n",
    "- **Public transport data:** Downloaded from PTV General Transit Feed Specification (GTFS) Data. As of September 2025.\n",
    "- **School data:** Dwonloaded from Department of Education. School Locations 2024.\n",
    "\n",
    "#### Given datasets\n",
    "- **Rental property listings:** Scraped from domain.com.au. As of September 2025.\n",
    "- **Moving annual median rent by suburb and town:** Victoria Government Families, Fairness and Housings Rental report. As of March quarter 2025.\n",
    "\n",
    "**Assumptions and limitations:**\n",
    "\n",
    "The rental dataset reflects only observed/scraped listings and may not necessarily be representative of all rental properties available within Victoria.\n",
    "\n",
    "Additionally, using several external datasets (resulting in 57 total features) may introduce potential multicollinearity between features (e.g. number of schools vs suburb population). Thus, the model may capture correlations rather than causal effects. However, we aim to address this through feature selection and feature importance.\n",
    "\n",
    "Finally, the external datasets span different time periods—some are current (e.g., crime and transport data), while others, such as the ABS Census (last updated in 2021), are less recent. This temporal mismatch may introduce inconsistencies, as demographic or social trends could have shifted in the intervening years. Thus, we assume that the characteristics captured in older datasets remain reasonably stable over time, and any changes since collection are gradual enough not to invalidate their use in modelling current rental prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f21f9d",
   "metadata": {},
   "source": [
    "## 2. Dataset building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e6810",
   "metadata": {},
   "source": [
    "The 5 external datasets were processed and cleaned to be merged with the rental property listings dataset.\n",
    "\n",
    "This means that for each rental listing, there will be rental specific attributes (e.g. number of bedrooms, number of schools within 2km), as well as suburb level attributes (e.g. suburb population, suburb crime index).\n",
    "\n",
    "This gives us 57 initial attributes/features, which need to be further cleaned, processed, filtered and selected to analyse rental prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2c06a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing_id', 'suburb', 'postcode', 'weekly_rent', 'bond',\n",
       "       'available_date', 'date_listed', 'days_listed', 'bedrooms', 'bathrooms',\n",
       "       'carspaces', 'property_type', 'address', 'lat', 'lon', 'photo_count',\n",
       "       'video_count', 'floorplans_count', 'virtual_tour', 'primary_type',\n",
       "       'secondary_type', 'agency', 'agent_names', 'land_area',\n",
       "       'num_metro_bus_stops', 'num_metro_tram_stops', 'num_metro_train_stops',\n",
       "       'num_regional_bus_stops', 'num_regional_train_stops', 'num_schools_2km',\n",
       "       'Median_age_persons', 'Median_mortgage_repay_monthly',\n",
       "       'Median_tot_prsnl_inc_weekly', 'Median_rent_weekly',\n",
       "       'Median_tot_fam_inc_weekly', 'Average_num_psns_per_bedroom',\n",
       "       'Median_tot_hhd_inc_weekly', 'Average_household_size',\n",
       "       'Owner occupied (%)', 'Mortgage (%)', 'Total rented (%)',\n",
       "       'Other tenure (%)', 'Unemployment', 'post_gradutae (%)',\n",
       "       'Graduate_diploma_certificate(%)', 'Bachelor (%)',\n",
       "       'Advanced_&_Diploma (%)', 'Certificate_level (%)', 'Total_persons',\n",
       "       'Population-2023', 'SAL_NAME21', 'incidents_recorded',\n",
       "       'rate_per_100000_population', 'population_est', 'crime_per_person',\n",
       "       'crime_index', 'crime_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "merged_dataset = pd.read_csv(\"../data/processed/real_estate/vic_rentals_all_enriched.csv\")\n",
    "merged_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a976de9",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebdd3d",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee1861",
   "metadata": {},
   "source": [
    "With the initial merged dataset, need to deal with any possible nan values per feature. This follows a 2 step process:\n",
    "\n",
    "**1. Mean imputation:** We create a lookup dictionary that is grouped by the property's suburb, property_type, bedrooms, and bathrooms and impute the feature's missing value according to the mean-aggregated dictionary value. Next, we create a relaxed version of this lookup dictionary on 'property_type', 'bedrooms' and use a similar pattern to impute more nans. This is done for the \"weekly_rent\" and \"carspaces\" features, which have the among the highest missing values. \n",
    "\n",
    "**2. Listwise deletion:** After imputing nans, there is significantly less remaining missing values so just drop them.\n",
    "\n",
    "Note: land_area was simply dropped and remove despite being a potential useful feature as it had too many missing values i.e 12329/12331\n",
    "\n",
    "**Assumptions and limitations**\n",
    "- Assumes features are missing at random and not systematically biased\n",
    "- Mean imputation may be too simple a method for imputation so may ignore natural variance in features. Though this is aimed to be addressed through the use of lookup dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d071146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nans(data):\n",
    "    missing_list = [(col, data[col].isnull().sum()) for col in data.columns]\n",
    "    non_nans = [(col, cnt) for col, cnt in missing_list if cnt != 0]\n",
    "    return sorted(non_nans, key=lambda x: x[1], reverse=True)  # sort by column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23675260",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daba01e",
   "metadata": {},
   "source": [
    "These numerical features were considered to determine outliers: ['weekly_rent', 'bedrooms', 'bathrooms', 'carspaces', 'num_metro_bus_stops', 'num_metro_tram_stops', 'num_schools_2km', 'incidents_recorded']\n",
    "\n",
    "We assume that extreme values are unrepresentative, which should be a valid assumption as there are only 27 rental properties above $3000, which should have little impact on model performance.\n",
    "\n",
    "We used 3000 as the as upper limit for the rental prices of houses in the Vic-Gov website is 2885. (https://www.housing.vic.gov.au/what-does-rent-cost-victoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8912ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero rent count: 16\n",
      "High outlier rent count: 27\n",
      "High bedroom count: 1\n"
     ]
    }
   ],
   "source": [
    "#Find how many 0 weekly_rent values there are\n",
    "zero_rent_count = (data[\"weekly_rent\"] == 0).sum()\n",
    "print(\"Zero rent count:\", zero_rent_count)\n",
    "\n",
    "#Find how many high outlier weekly_rent values there are i.e above 3000\n",
    "highoutlier_rent_count = (data[\"weekly_rent\"] >= 3000).sum()\n",
    "print(\"High outlier rent count:\", highoutlier_rent_count)\n",
    "\n",
    "#Find how many data points with 50 or more bedrooms\n",
    "high_bedroom_count = (data[\"bedrooms\"] >= 50).sum()\n",
    "print(\"High bedroom count:\", high_bedroom_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b05d2",
   "metadata": {},
   "source": [
    "Surprisingly, not many outliers were detected. Removing these outliers gives the following distribution for the numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c9df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekly_rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>carspaces</th>\n",
       "      <th>num_metro_bus_stops</th>\n",
       "      <th>num_metro_tram_stops</th>\n",
       "      <th>num_schools_2km</th>\n",
       "      <th>incidents_recorded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "      <td>12018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>621.903977</td>\n",
       "      <td>2.720835</td>\n",
       "      <td>1.587203</td>\n",
       "      <td>1.626061</td>\n",
       "      <td>61.837910</td>\n",
       "      <td>20.948910</td>\n",
       "      <td>8.061075</td>\n",
       "      <td>13259.928384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>249.176926</td>\n",
       "      <td>1.081993</td>\n",
       "      <td>0.629443</td>\n",
       "      <td>0.946937</td>\n",
       "      <td>43.221829</td>\n",
       "      <td>35.017988</td>\n",
       "      <td>4.798088</td>\n",
       "      <td>5828.544925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>490.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>560.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13140.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>683.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17495.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34620.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        weekly_rent      bedrooms     bathrooms     carspaces  \\\n",
       "count  12018.000000  12018.000000  12018.000000  12018.000000   \n",
       "mean     621.903977      2.720835      1.587203      1.626061   \n",
       "std      249.176926      1.081993      0.629443      0.946937   \n",
       "min       33.000000      1.000000      1.000000      1.000000   \n",
       "25%      490.000000      2.000000      1.000000      1.000000   \n",
       "50%      560.000000      3.000000      2.000000      1.000000   \n",
       "75%      683.000000      4.000000      2.000000      2.000000   \n",
       "max     3000.000000     11.000000     12.000000     22.000000   \n",
       "\n",
       "       num_metro_bus_stops  num_metro_tram_stops  num_schools_2km  \\\n",
       "count         12018.000000          12018.000000     12018.000000   \n",
       "mean             61.837910             20.948910         8.061075   \n",
       "std              43.221829             35.017988         4.798088   \n",
       "min               0.000000              0.000000         0.000000   \n",
       "25%              22.000000              0.000000         4.000000   \n",
       "50%              66.000000              0.000000         8.000000   \n",
       "75%              96.000000             35.000000        12.000000   \n",
       "max             183.000000            127.000000        23.000000   \n",
       "\n",
       "       incidents_recorded  \n",
       "count        12018.000000  \n",
       "mean         13259.928384  \n",
       "std           5828.544925  \n",
       "min             77.000000  \n",
       "25%           9525.000000  \n",
       "50%          13140.500000  \n",
       "75%          17495.333333  \n",
       "max          34620.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove outliers rows\n",
    "data = data[(data[\"weekly_rent\"] > 0) & (data[\"weekly_rent\"] <= 3000) & (data[\"bedrooms\"] < 50)]\n",
    "#Looking at numerical variables\n",
    "data[['weekly_rent', 'bedrooms', 'bathrooms', 'carspaces', 'num_metro_bus_stops', 'num_metro_tram_stops', 'num_schools_2km', 'incidents_recorded']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fff95",
   "metadata": {},
   "source": [
    "Finally, after encoding categorical variables (extracting time features from 'available_date'), our dataset is finally cleaned and ready to be analysed to determine important features for predicting rental prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4514b8f",
   "metadata": {},
   "source": [
    "## 4. Modelling Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e2ee8",
   "metadata": {},
   "source": [
    "Models: Random Forest Regressor and GX boost were selected with their ability to capture complex relationships in data and a useful feature importance function to help understand which features are were most important in model predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad151783",
   "metadata": {},
   "source": [
    "### Feature Engeering And Encoding\n",
    "\n",
    "Time data was feature engineered to hour, day and month; and then encoded using cyclic encoding to help model capture potential seasonal change in rent prices.\n",
    "\n",
    "Frequency encoding was used for non-numerical features i.e postcode, property_type and agency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering time data\n",
    "data['available_date'] = pd.to_datetime(data['available_date'], errors='coerce')\n",
    "data['available_day'] = data['available_date'].dt.day\n",
    "data['available_month'] = data['available_date'].dt.month   \n",
    "data['available_year'] = data['available_date'].dt.year\n",
    "data = data.drop(columns=['available_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode month cyclically \n",
    "data['month_sin'] = np.sin(data['available_month'] / 12 * 2 * np.pi)\n",
    "data['month_cos'] = np.cos(data['available_month'] / 12 * 2 * np.pi)\n",
    "data = data.drop(columns=['available_month'])\n",
    "\n",
    "#Encode day cyclically\n",
    "data['day_sin'] = np.sin(data['available_day'] / 31 * 2 * np.pi)\n",
    "data['day_cos'] = np.cos(data['available_day'] / 31 * 2 * np.pi)\n",
    "data = data.drop(columns=['available_day'])\n",
    "\n",
    "#Frequency encoding for Non-numericeal columns\n",
    "post_freq = data['postcode'].value_counts(normalize=True)\n",
    "data['postcode'] = data['postcode'].map(post_freq)\n",
    "property_freq = data['property_type'].value_counts(normalize=True)\n",
    "data['property_type'] = data['property_type'].map(property_freq)\n",
    "agency_freq = data['agency'].value_counts(normalize=True)\n",
    "data['agency'] = data['agency'].map(agency_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0ac75",
   "metadata": {},
   "source": [
    "#### Limitations and Assumptions\n",
    "\n",
    "We assume that postcode, propety_type and agency have certain catergories(e.g a common postcode, popular property type,etc.) that can influence weekly rent prices. \n",
    "\n",
    "Cycle encodinng treats and months and day pattern as if patterns always repeat identically, training only on 2025 might cause bias in the predictions of data for a different year. This shouldn't be an issue as this data set will not be used in forcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43161202",
   "metadata": {},
   "source": [
    "### Data leakage\n",
    "\n",
    "Certain features in the data such as 'median_rent_weekly', 'median_morgage_repay_monthly' and 'bond' can cause data leakage and hence removed. (bond was remove earlier in preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f503913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop lat and long for modeling\n",
    "data = data.drop(columns=['lat', 'lon', 'Median_rent_weekly', 'Median_mortgage_repay_monthly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d4414",
   "metadata": {},
   "source": [
    "All data was rescaled using the Standardize Scalar method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e73e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize scalar, resacling all data. (can target specific columns if needed)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ce8d3",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe8a13",
   "metadata": {},
   "source": [
    "Feature Selection was conducted using Mutual Information(MI) as we hav 42 features. 20 Features were selected from the 42.\n",
    "\n",
    "Results show that models without feature selection performes significantly better with average r^2 of 0.7 and average MAE of 70 compared to mdoels with feature selection with average r^2  0.25 and average MAE of 126.5.\n",
    "\n",
    "Cause: likely due to MI only capturing univeriate relationships between one variable vs target variable while our data contains strong multivariable interactions; hence MI fails to compare them and discards useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MI\n",
    "mi = mutual_info_regression(X, y, discrete_features=\"auto\", random_state=0)\n",
    "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "k = 20\n",
    "selected_features = mi_scores.head(k).index.tolist()\n",
    "\n",
    "X_selection = X[selected_features]\n",
    "X_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a4a31",
   "metadata": {},
   "source": [
    "Models \n",
    "Key features: bathrooms, bedrooms and Bachelor (%) were signficantly more important than every other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5838cac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.232121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelor (%)</td>\n",
       "      <td>0.166932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.121920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>days_listed</td>\n",
       "      <td>0.037450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_metro_bus_stops</td>\n",
       "      <td>0.025811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Median_tot_fam_inc_weekly</td>\n",
       "      <td>0.025658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Median_tot_prsnl_inc_weekly</td>\n",
       "      <td>0.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_metro_tram_stops</td>\n",
       "      <td>0.024612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agency</td>\n",
       "      <td>0.021993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Graduate_diploma_certificate(%)</td>\n",
       "      <td>0.020688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance\n",
       "0                        bathrooms    0.232121\n",
       "1                     Bachelor (%)    0.166932\n",
       "2                         bedrooms    0.121920\n",
       "3                      days_listed    0.037450\n",
       "4              num_metro_bus_stops    0.025811\n",
       "5        Median_tot_fam_inc_weekly    0.025658\n",
       "6      Median_tot_prsnl_inc_weekly    0.025487\n",
       "7             num_metro_tram_stops    0.024612\n",
       "8                           agency    0.021993\n",
       "9  Graduate_diploma_certificate(%)    0.020688"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feature_importance = pd.read_csv(\"../data/outputs/rf_importance_features.csv\")\n",
    "rf_feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ef1a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.266131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.210042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelor (%)</td>\n",
       "      <td>0.143386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Median_tot_fam_inc_weekly</td>\n",
       "      <td>0.084951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Certificate_level (%)</td>\n",
       "      <td>0.031082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Median_tot_prsnl_inc_weekly</td>\n",
       "      <td>0.026502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Graduate_diploma_certificate(%)</td>\n",
       "      <td>0.024573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_metro_tram_stops</td>\n",
       "      <td>0.022660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>days_listed</td>\n",
       "      <td>0.022043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>population_est</td>\n",
       "      <td>0.021998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance\n",
       "0                        bathrooms    0.266131\n",
       "1                         bedrooms    0.210042\n",
       "2                     Bachelor (%)    0.143386\n",
       "3        Median_tot_fam_inc_weekly    0.084951\n",
       "4            Certificate_level (%)    0.031082\n",
       "5      Median_tot_prsnl_inc_weekly    0.026502\n",
       "6  Graduate_diploma_certificate(%)    0.024573\n",
       "7             num_metro_tram_stops    0.022660\n",
       "8                      days_listed    0.022043\n",
       "9                   population_est    0.021998"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gxboost_feature_importance = pd.read_csv(\"../data/outputs/gxboost_importance_features.csv\")\n",
    "gxboost_feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90d331",
   "metadata": {},
   "source": [
    "## 5. Liveability & affordability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a9d41",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Components that go into livability score of a suburb are: \n",
    "- number of schools  \n",
    "- number of train, bus and tram stops \n",
    "- crime index as normalised (0-100) score of total offenses recorded within the suburb, where below 20 is considered low crime\n",
    "\n",
    "To quanitify the livability we assigned weights to the components above, the assumption was that crime is the most important indicator of suburb's quality hence its weight of 0.4. Number of schools is the second most important factor with weight 0.3, then number of public transport stops with overall weight of 0.3. \n",
    "\n",
    "### Affordability calculation \n",
    "\n",
    "Affordability was quantified as ratio of weekly rent to median weekly household income in a suburb. \n",
    "\n",
    "Graph below shows the top 10 suburbs with highest affordability score. \n",
    "\n",
    "![Top 10 Affordability](../graphs/Most_affordable.png)\n",
    "\n",
    "The bar chart below shows 10 subrubs with highest livability score. \n",
    "\n",
    "![Top 10 Livability](../graphs/Most_livable.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067308f",
   "metadata": {},
   "source": [
    "## 6. Rent Forecasting\n",
    "\n",
<<<<<<< HEAD
    "The model that we incorporated was time series with ... "
=======
    "The model we incorporated for rent forecasting was a time series model using Auto ARIMA, designed to capture seasonal trends in quarterly rental data from 2000 to 2024. Each suburb and property type was modeled separately to account for local variations in rental dynamics. The model produced five-year forecasts (2025–2029), allowing us to estimate future rent trajectories across different property categories. The results highlight that 2-bedroom houses and flats were the most predictable, while larger properties such as 3- and 4-bedroom dwellings showed greater volatility, likely reflecting lower transaction volumes and higher sensitivity to economic fluctuations. The suburb with the largest increase in predicted growth is Mildura while the lowest is Clayton\n",
    "\n",
    "![Mildura Forecast](../graphs/mildura_forecast.png)\n",
    "\n",
    "![Clayton Forecast](../graphs/clayton_forecast.png)"
>>>>>>> 6f173d95e7157c0f1b5cf096c1a6eac5c5e7235d
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74f8b7",
   "metadata": {},
   "source": [
    "### Findings \n",
    "\n",
    "Our model allowed as to forecast weekly rental price for each quarter of the next 5 years. When we ran the model on validation set with historical data it resulted in accuracy of ... % which is satisfactory. \n",
    "\n",
    "![Forecast example](../graphs/forecast.png)\n",
    "\n",
    "![Forecast example 2](../graphs/forecast_2.png)\n",
    "\n",
    "\n",
    "\n",
    "### Below is an analysis of our predictions, divided into sections:\n",
    "\n",
    "1. Average growth of rental prices by suburbs, first on the overall level and then computed for both only houses and only apartments\n",
    "\n",
    "Below are bar charts showing 10 suburbs with highest predicted rental price increase: overall, only houses, only apartments.\n",
    "\n",
    "![Top 10 Overall](../graphs/Overall_top_growth.png)\n",
    "\n",
    "![Top 10 Houses](../graphs/Houses_top_growth.png)\n",
    "\n",
    "![Top 10 Apartments](../graphs/Apartments_top_growth.png)\n",
    "\n",
    "\n",
    "Below are graphs showing similar analysis but for bottom 10 subrubs.\n",
    "\n",
    "![Bottom 10 Overall](../graphs/Overall_bottom_growth.png)\n",
    "\n",
    "![Bottom 10 Houses](../graphs/Houses_bottom_growth.png)\n",
    "\n",
    "![Bottom 10 Apartments](../graphs/Apartments_bottom_growth.png)\n",
    "\n",
    "2. Return on Investment analysis done by including current property prices for houses and apartments (extracted from the Victorian\n",
    "goverment website). Question that we're answering here is: \n",
    "\n",
    "### What property type (house/apartment) and in which suburb should I buy to maximize my return on investment (ROI)? \n",
    "\n",
    "ROI is calculated as average rental income over next 5 years divided by the median property price today. \n",
    "\n",
    "We're limited by the property price data which includes only median prices on the suburb level. Therefore we can't analyze based \n",
    "on the number of bedrooms and have to stay with the house/unit granularity.\n",
    "\n",
    "The bar chart below shows the 5 investments (property type & subrub) with the highest 5 year return on investemnt. \n",
    "\n",
    "![Top 5 ROI](../graphs/ROI_overall.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccb3df",
   "metadata": {},
   "source": [
    "## 7. Overall Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ba90f",
   "metadata": {},
   "source": [
    "- Temporal mismatches in rental prices: Rental data reflects current listings, while external datasets (e.g., census and population) are lagging indicators\n",
    "\n",
    "- Sample bias: Scraped domain.com.au dataset may not be representative of the Victorian rental market\n",
    "\n",
    "- Correlation or causation (even though causation) for feature importance when determining rental prices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
